<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/scripts/add_specialty_names.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/scripts/add_specialty_names.py" />
              <option name="originalContent" value="&#10;" />
              <option name="updatedContent" value="import csv&#10;from pathlib import Path&#10;import argparse&#10;import sys&#10;&#10;# Map specialty IDs to names (common PetClinic mapping)&#10;mapping = {&#10;    '1': 'radiology',&#10;    '2': 'surgery',&#10;    '3': 'dentistry'&#10;}&#10;&#10;parser = argparse.ArgumentParser(description='Add specialtyName column to vets CSV')&#10;parser.add_argument('--input', '-i', help='Input CSV path', default=None)&#10;parser.add_argument('--output', '-o', help='Output CSV path', default=None)&#10;args = parser.parse_args()&#10;&#10;base = Path(__file__).resolve().parents[1] / 'src' / 'test' / 'resources' / 'data'&#10;input_file = Path(args.input) if args.input else base / 'vets.csv'&#10;output_file = Path(args.output) if args.output else base / 'vets_with_specialtyName.csv'&#10;&#10;# Ensure input exists&#10;if not input_file.exists():&#10;    print(f'Input file not found: {input_file}', file=sys.stderr)&#10;    sys.exit(2)&#10;&#10;with input_file.open(newline='', encoding='utf-8') as infile, output_file.open('w', newline='', encoding='utf-8') as outfile:&#10;    reader = csv.reader(infile)&#10;    writer = csv.writer(outfile)&#10;&#10;    try:&#10;        header = next(reader)&#10;    except StopIteration:&#10;        # empty file&#10;        writer.writerow(['firstName','lastName','specialtyIds','specialtyName'])&#10;        print(f'Wrote empty output: {output_file}')&#10;        sys.exit(0)&#10;&#10;    # If header already contains specialtyName, normalize to single column&#10;    hdr = [h for h in header if h != 'specialtyName']&#10;    new_header = hdr + ['specialtyName']&#10;    writer.writerow(new_header)&#10;&#10;    # Determine index of specialtyIds in original header (if header names different)&#10;    try:&#10;        idx = header.index('specialtyIds')&#10;    except ValueError:&#10;        # assume third column&#10;        idx = 2&#10;&#10;    for row in reader:&#10;        # pad short rows&#10;        if len(row) &lt;= idx:&#10;            writer.writerow(row + [''])&#10;            continue&#10;        specialty_ids = row[idx].strip()&#10;        ids = [s.strip() for s in specialty_ids.split(',') if s.strip()]&#10;        names = [mapping.get(i, '') for i in ids]&#10;        specialty_name = ','.join(names)&#10;        # Build new row preserving original non-specialtyName fields in order (excluding any existing specialtyName)&#10;        base_row = [row[i] if i &lt; len(row) else '' for i, h in enumerate(header) if h != 'specialtyName']&#10;        new_row = base_row + [specialty_name]&#10;        writer.writerow(new_row)&#10;&#10;print(f'Wrote: {output_file}')" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/scripts/collapse_vet_specialties.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/scripts/collapse_vet_specialties.py" />
              <option name="updatedContent" value="import csv&#10;from pathlib import Path&#10;import shutil&#10;&#10;base = Path(__file__).resolve().parents[1] / 'src' / 'test' / 'resources' / 'data'&#10;file_path = base / 'vets.csv'&#10;backup_path = base / 'vets.csv.pre_collapse.bak'&#10;&#10;mapping = {&#10;    '1': 'radiology',&#10;    '2': 'surgery',&#10;    '3': 'dentistry'&#10;}&#10;&#10;if not file_path.exists():&#10;    print(f'File not found: {file_path}')&#10;    raise SystemExit(2)&#10;&#10;# backup&#10;shutil.copy2(file_path, backup_path)&#10;print(f'Backup created: {backup_path}')&#10;&#10;rows_changed = 0&#10;rows_total = 0&#10;&#10;temp_path = base / 'vets.csv.tmp'&#10;with file_path.open(newline='', encoding='utf-8') as infile, temp_path.open('w', newline='', encoding='utf-8') as outfile:&#10;    reader = csv.reader(infile)&#10;    writer = csv.writer(outfile)&#10;&#10;    header = next(reader, None)&#10;    if header is None:&#10;        print('Empty file, nothing to do')&#10;        temp_path.unlink()&#10;        raise SystemExit(0)&#10;&#10;    # decide if specialtyName column exists&#10;    has_specialtyName = 'specialtyName' in header&#10;    # build normalized header&#10;    hdr_no_sn = [h for h in header if h != 'specialtyName']&#10;    new_header = hdr_no_sn + ['specialtyName']&#10;    writer.writerow(new_header)&#10;&#10;    # find index of specialtyIds in original header&#10;    try:&#10;        idx = header.index('specialtyIds')&#10;    except ValueError:&#10;        idx = 2  # fallback&#10;&#10;    for row in reader:&#10;        rows_total += 1&#10;        # ensure row has at least idx&#10;        while len(row) &lt;= idx:&#10;            row.append('')&#10;&#10;        orig_ids = row[idx].strip()&#10;        # remove surrounding quotes are handled by csv&#10;        if orig_ids == '':&#10;            first_id = ''&#10;            first_name = ''&#10;        else:&#10;            ids = [s.strip() for s in orig_ids.split(',') if s.strip()]&#10;            first_id = ids[0] if ids else ''&#10;            first_name = mapping.get(first_id, '')&#10;&#10;        # build base_row excluding any existing specialtyName column&#10;        base_row = [row[i] if i &lt; len(row) and header[i] != 'specialtyName' else '' for i in range(len(header)) if header[i] != 'specialtyName']&#10;        # replace specialtyIds field value (it's at the position where header == 'specialtyIds' in base_row)&#10;        # find position of specialtyIds in new_header&#10;        try:&#10;            new_idx = new_header.index('specialtyIds')&#10;        except ValueError:&#10;            new_idx = 2&#10;        # ensure base_row long enough&#10;        while len(base_row) &lt;= new_idx:&#10;            base_row.append('')&#10;        base_row[new_idx] = first_id&#10;&#10;        new_row = base_row + [first_name]&#10;&#10;        # count change if original had multiple ids&#10;        if ',' in orig_ids:&#10;            rows_changed += 1&#10;&#10;        writer.writerow(new_row)&#10;&#10;# replace original&#10;temp_path.replace(file_path)&#10;print(f'Wrote collapsed vets.csv; total rows={rows_total}, rows changed={rows_changed}')&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/scripts/merge_owners_pets.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/scripts/merge_owners_pets.py" />
              <option name="updatedContent" value="import csv&#10;from pathlib import Path&#10;import sys&#10;&#10;base = Path(__file__).resolve().parents[1] / 'src' / 'test' / 'resources' / 'data'&#10;owners_file = base / 'owners.csv'&#10;pets_file = base / 'pets.csv'&#10;output_file = base / 'user.csv'&#10;&#10;if not owners_file.exists() or not pets_file.exists():&#10;    print('Missing owners.csv or pets.csv in data folder', file=sys.stderr)&#10;    sys.exit(2)&#10;&#10;with owners_file.open(newline='', encoding='utf-8') as of, pets_file.open(newline='', encoding='utf-8') as pf:&#10;    owners_reader = csv.reader(of)&#10;    pets_reader = csv.reader(pf)&#10;&#10;    owners_header = next(owners_reader, None)&#10;    pets_header = next(pets_reader, None)&#10;&#10;    owners_rows = list(owners_reader)&#10;    pets_rows = list(pets_reader)&#10;&#10;    n_owners = len(owners_rows)&#10;    n_pets = len(pets_rows)&#10;&#10;    n = min(n_owners, n_pets)&#10;&#10;    if n_owners != n_pets:&#10;        print(f'Warning: owners rows={n_owners}, pets rows={n_pets}. Will merge first {n} rows.')&#10;&#10;    with output_file.open('w', newline='', encoding='utf-8') as out:&#10;        writer = csv.writer(out)&#10;        # header: firstName,lastName,address,city,telephone,petName,birthDate,typeId,typeName&#10;        writer.writerow(['firstName','lastName','address','city','telephone','petName','birthDate','typeId','typeName'])&#10;&#10;        for i in range(n):&#10;            owner = owners_rows[i]&#10;            pet = pets_rows[i]&#10;            # owner expected: firstName,lastName,address,city,telephone&#10;            firstName = owner[0] if len(owner) &gt; 0 else ''&#10;            lastName = owner[1] if len(owner) &gt; 1 else ''&#10;            address = owner[2] if len(owner) &gt; 2 else ''&#10;            city = owner[3] if len(owner) &gt; 3 else ''&#10;            telephone = owner[4] if len(owner) &gt; 4 else ''&#10;            # pet expected: name,birthDate,typeId,typeName&#10;            petName = pet[0] if len(pet) &gt; 0 else ''&#10;            birthDate = pet[1] if len(pet) &gt; 1 else ''&#10;            typeId = pet[2] if len(pet) &gt; 2 else ''&#10;            typeName = pet[3] if len(pet) &gt; 3 else ''&#10;&#10;            writer.writerow([firstName,lastName,address,city,telephone,petName,birthDate,typeId,typeName])&#10;&#10;print(f'Wrote {output_file} with {n} rows (owners={n_owners}, pets={n_pets})')&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>